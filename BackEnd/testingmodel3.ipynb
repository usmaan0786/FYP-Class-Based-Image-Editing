{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7111141,"sourceType":"datasetVersion","datasetId":4100282},{"sourceId":7111145,"sourceType":"datasetVersion","datasetId":4100286}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pathlib\nimport time\nimport datetime\nimport imageio\nfrom glob import glob\n\nimport tensorflow as tf\nimport numpy as np \nimport tensorflow.keras.backend as K\nimport tensorflow_addons as tfa\n\nfrom matplotlib import pyplot as plt\nfrom IPython import display\nfrom termcolor import colored\nfrom tqdm import tqdm\nfrom IPython.display import Image\nimport PIL\nfrom PIL import ImageDraw\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:22.296126Z","iopub.execute_input":"2023-12-03T08:55:22.296508Z","iopub.status.idle":"2023-12-03T08:55:22.302854Z","shell.execute_reply.started":"2023-12-03T08:55:22.296477Z","shell.execute_reply":"2023-12-03T08:55:22.301821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def color_print(print_str, print_color='green'):\n    \n    '''print in given  color (default green)'''\n    print(colored(print_str,print_color))\n    \ndef set_seed(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    print(f'setting seed to {seed}')\n\nclass CFG:\n    \n    IMG_WIDTH =  512\n    IMG_HEIGHT = 512\n    \n    resize_height = 512\n    resize_width = 512\n    \n    LAMBDA = 10\n\n    BUFFER_SIZE = 100\n    \n    BATCH_SIZE = 2\n    \n    cache= 50\n    \n    learning_rate = 0.00025\n    \n    seed = 7 \n    \nset_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:22.521590Z","iopub.execute_input":"2023-12-03T08:55:22.521994Z","iopub.status.idle":"2023-12-03T08:55:22.530985Z","shell.execute_reply.started":"2023-12-03T08:55:22.521959Z","shell.execute_reply":"2023-12-03T08:55:22.529979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"white_dir = '/kaggle/input/green-shirts-only/Green Shirts'\nblack_dir = '/kaggle/input/black-shirts-only/Black Shirts'\n\nplt.figure(figsize=(16,8))\n\nimg = plt.imread(white_dir + '/' + os.listdir(white_dir)[1])\nplt.imshow(img)\nplt.axis('off')\nplt.title('sample image')\nprint(f'Image dimensions {img.shape}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:24.390976Z","iopub.execute_input":"2023-12-03T08:55:24.391368Z","iopub.status.idle":"2023-12-03T08:55:24.767205Z","shell.execute_reply.started":"2023-12-03T08:55:24.391335Z","shell.execute_reply":"2023-12-03T08:55:24.765975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_file):\n    '''load a image file'''\n    image = tf.io.read_file(image_file)\n    image = tf.io.decode_jpeg(image)\n    \n    return image\n\n\ndef random_crop(image):\n    '''randomly crop image into defined size '''\n    cropped_image = tf.image.random_crop(image, size=[CFG.IMG_HEIGHT, CFG.IMG_WIDTH, 3])\n\n    return cropped_image\n\n\ndef normalize(image):\n    '''normalizing the images to [-1, 1]'''\n    image = tf.cast(image, tf.float32)\n    image = (image / 127.5) - 1\n    return image\n\n\ndef de_normalize(image):\n    '''De normalize the image to be in range (0,1)'''\n    \n    return (image * 0.5) + 0.5 \n\ndef image_augmentations(image):\n    '''perform spatial augmentations (rotation and flips) on input image'''\n    \n    # --------------------rotations----------\n    #rotation probabliity\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    if p_rotate > .8:\n        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n    elif p_rotate > .6:\n        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n    elif p_rotate > .4:\n        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n        \n    \n    # ----------------------Flips---------------------\n    p_flip = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    if p_flip > 0.7:    \n        image = tf.image.random_flip_left_right(image)\n    elif p_flip < 0.3:\n        image = tf.image.random_flip_up_down(image)\n    \n    return image\n\ndef random_jitter(image):\n    '''resize and randommly crop the input image'''\n    \n#     # resizing image\n    image = tf.image.resize(image, size=(CFG.resize_height, CFG.resize_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n#     randomly cropping to 512,512\n    image = random_crop(image)\n    \n    return image\n\ndef preprocess_image_train(image):\n    image = load_image(image)\n    image = random_jitter(image)\n    image= image_augmentations(image)\n    image = normalize(image)\n    return image\n\n\n#same function, withou the augemntation\ndef preprocess_image_eval(image):\n    image = load_image(image)\n    image = random_jitter(image)\n    image = normalize(image)\n    return image\n\ndef create_img_dataset(directory,\n                       image_preprocess_fn,\n                       image_extension = 'jpg',         \n                       repeat=True\n                      ):\n    '''create a tf dataset object from a directory of images'''\n    img_list = glob(directory+f'/*{image_extension}')\n    \n    dataset = tf.data.Dataset.list_files(img_list)\n    \n    dataset = dataset.map(image_preprocess_fn, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    if repeat :\n        dataset = dataset.repeat()\n              \n    dataset = dataset.shuffle(CFG.BUFFER_SIZE) \n    dataset = dataset.batch(CFG.BATCH_SIZE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:24.768885Z","iopub.execute_input":"2023-12-03T08:55:24.769401Z","iopub.status.idle":"2023-12-03T08:55:24.786968Z","shell.execute_reply.started":"2023-12-03T08:55:24.769362Z","shell.execute_reply":"2023-12-03T08:55:24.785896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"white_Dataset = create_img_dataset(directory = white_dir,image_preprocess_fn = preprocess_image_train)\n\n#without augmentation\nwhite_eval = create_img_dataset(directory = white_dir, image_preprocess_fn = preprocess_image_eval)\n\nfig,ax = plt.subplots(figsize=(16,8))\n    \ninp_img = next(iter(white_Dataset))\nplt.imshow(de_normalize(inp_img[0]))\nplt.title('Sample white Shirt image')\nprint(f'Image dimensions {inp_img[0].shape}')\nplt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:24.857033Z","iopub.execute_input":"2023-12-03T08:55:24.857417Z","iopub.status.idle":"2023-12-03T08:55:26.604622Z","shell.execute_reply.started":"2023-12-03T08:55:24.857386Z","shell.execute_reply":"2023-12-03T08:55:26.603736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"black_Dataset = create_img_dataset(directory = black_dir,image_preprocess_fn = preprocess_image_train)\n#without augmentation\n\nblack_eval = create_img_dataset(directory = black_dir, image_preprocess_fn = preprocess_image_eval)\n\nfig,ax = plt.subplots(figsize=(16,8))\n    \ninp_img = next(iter(black_Dataset))\nplt.imshow(de_normalize(inp_img[0]))\nplt.title('Sample black image')\nplt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:28.330562Z","iopub.execute_input":"2023-12-03T08:55:28.331247Z","iopub.status.idle":"2023-12-03T08:55:30.425693Z","shell.execute_reply.started":"2023-12-03T08:55:28.331210Z","shell.execute_reply":"2023-12-03T08:55:30.424799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_Dataset = tf.data.Dataset.zip((white_Dataset,black_Dataset))","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:32.419617Z","iopub.execute_input":"2023-12-03T08:55:32.420518Z","iopub.status.idle":"2023-12-03T08:55:32.429434Z","shell.execute_reply.started":"2023-12-03T08:55:32.420484Z","shell.execute_reply":"2023-12-03T08:55:32.428440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_initializer = tf.random_normal_initializer(mean=0.0, stddev=0.02)\n\n\ngamma_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \ndef downsample(input_layer,\n               filters,\n               name,\n               size=3, \n               strides=2, \n               activation=tf.keras.layers.ReLU(), \n               ):\n    \n    '''perform a downsampling by applying a convolution,followed by instance norm and activation'''\n    conv = tf.keras.layers.Conv2D(filters, \n                                  size, \n                                  strides=strides, \n                                  padding='same', \n                                  use_bias=False, \n                                  kernel_initializer=conv_initializer, \n                                  name=f'encoder_{name}')(input_layer)\n \n    conv = tfa.layers.InstanceNormalization(axis=-1,gamma_initializer=gamma_initializer)(conv)\n        \n    conv = activation(conv)\n\n    return conv\n\ndef upsample(input_layer,\n             filters,\n             name,\n             size=3,\n             strides=2,\n             activation='relu'):\n    \n    res = tf.keras.layers.Conv2DTranspose(filters, size, \n                                          strides=strides, \n                                          padding='same', \n                                          use_bias=False, \n                                          kernel_initializer=conv_initializer, \n                                          name=f'decoder_{name}')(input_layer)\n\n    res = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(res)\n\n    res =  tf.keras.layers.Activation(activation)(res)\n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:34.177120Z","iopub.execute_input":"2023-12-03T08:55:34.177531Z","iopub.status.idle":"2023-12-03T08:55:34.206341Z","shell.execute_reply.started":"2023-12-03T08:55:34.177495Z","shell.execute_reply":"2023-12-03T08:55:34.205375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def residual_block(input_layer, size=3, strides=1, name='block_x'): \n    '''performs 2 convolutions followed by an added skip connection with the input'''\n    \n    filters = input_layer.shape[-1]\n    block = tf.keras.layers.Conv2D(filters, \n                     size,\n                     strides=strides,\n                     padding='same',\n                     use_bias=False, \n                     kernel_initializer=conv_initializer,\n                     name=f'residual_{name}')(input_layer)\n    \n    block = tf.keras.layers.Activation('relu')(block)\n    block = tf.keras.layers.Conv2D(filters, size, strides=strides, padding='same', use_bias=False, \n                     kernel_initializer=conv_initializer, name=f'transformer_{name}_2')(block)    \n    \n    res = tf.keras.layers.Add()([block, input_layer])\n\n    return res\n\ndef concat_layer(layer_1,layer_2,name):\n    '''concatenation of layers for skip connections'''\n    return tf.keras.layers.Concatenate(name=name)([layer_1,layer_2])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:34.569419Z","iopub.execute_input":"2023-12-03T08:55:34.569816Z","iopub.status.idle":"2023-12-03T08:55:34.578239Z","shell.execute_reply.started":"2023-12-03T08:55:34.569783Z","shell.execute_reply":"2023-12-03T08:55:34.576912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_generator(num_residual_connections=6):\n    \n    input_ = tf.keras.layers.Input(shape=(CFG.IMG_WIDTH,CFG.IMG_HEIGHT,3),  name='input_layer')\n    \n    #-----------------------ENCODER-------------------------------\n    enc1 = downsample(input_layer = input_, filters=64,  strides =  1, size=7, name='dwn_1')    \n    enc2 = downsample(input_layer=enc1,filters= 128,size =  3, strides =  2, name='dwn_2')\n    enc3 = downsample(input_layer=enc2, filters=256,size =  3, strides =2, name='dwn_3')        \n    enc4 = downsample(input_layer=enc3, filters=256,size =  3, strides =2, name='dwn_4')        \n    \n    #-----------------------Residual connections-------------------------------\n    x = enc4\n    for n in range(num_residual_connections):\n        x = residual_block(input_layer=x, name=f'res_block_{n+1}')     # (bs, 64, 64, 256)\n\n    #-----------------------DECODER-------------------------------\n    x_skip = concat_layer(layer_1=x,layer_2=enc4,name='skip_1')               \n    dec1 = upsample(x_skip,filters=256 ,name='upsam_1')\n    \n    x_skip = concat_layer(layer_1=dec1,layer_2=enc3,name='skip_2')               \n    dec_2 = upsample(x_skip, filters=128,name='upsam_2')\n       \n    x_skip = concat_layer(layer_1=dec_2,layer_2=enc2,name='skip_3')               \n    dec_3 = upsample(x_skip, filters= 64,name='upsam_3')\n    \n    x_skip = concat_layer(layer_1=dec_3,\n                          layer_2=enc1,\n                          name='skip_final')\n\n    output = tf.keras.layers.Conv2D(filters = 3,kernel_size = 7, strides=1, padding='same', \n                                  kernel_initializer=conv_initializer, use_bias=False, activation='tanh', \n                                  name='output_layer')(x_skip) \n    \n    return tf.keras.models.Model(inputs=input_,outputs=output)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:34.803487Z","iopub.execute_input":"2023-12-03T08:55:34.804162Z","iopub.status.idle":"2023-12-03T08:55:34.814931Z","shell.execute_reply.started":"2023-12-03T08:55:34.804125Z","shell.execute_reply":"2023-12-03T08:55:34.813864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"white2black_gen = get_generator()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:42.658509Z","iopub.execute_input":"2023-12-03T08:55:42.658921Z","iopub.status.idle":"2023-12-03T08:55:43.132268Z","shell.execute_reply.started":"2023-12-03T08:55:42.658884Z","shell.execute_reply":"2023-12-03T08:55:43.131166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"black2white_gen = get_generator()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:43.134022Z","iopub.execute_input":"2023-12-03T08:55:43.134357Z","iopub.status.idle":"2023-12-03T08:55:43.609507Z","shell.execute_reply.started":"2023-12-03T08:55:43.134328Z","shell.execute_reply":"2023-12-03T08:55:43.608541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def PATCH_discriminator(leak_rate = 0.2):\n    '''PATCH discriminator network'''\n    leaky_relu = tf.keras.layers.LeakyReLU(leak_rate)\n\n    \n    input_ = tf.keras.layers.Input(shape=(CFG.IMG_WIDTH,CFG.IMG_HEIGHT,3),  name='input_layer')\n    # Encoder    \n    x = downsample(input_layer = input_, filters=64,  strides =  2, size=4, name='dwn_1',activation = leaky_relu)    #h,w =256\n    x = downsample(input_layer = x, filters=128,  strides =  2, size=4, name='dwn_2',activation = leaky_relu)        #h,w =128\n    x = downsample(input_layer = x, filters=256,  strides =  2, size=4, name='dwn_3',activation = leaky_relu)        #h,w = 64\n    x = downsample(input_layer = x, filters=512,  strides =  2, size=4, name='dwn_4',activation = leaky_relu)        #h,w = 32\n    x = downsample(input_layer = x, filters=512,  strides =  1, size=4, name='dwn_5',activation = leaky_relu)        #h,w = 32\n    \n    output = tf.keras.layers.Conv2D(1, 4, strides=1, padding='valid', kernel_initializer=conv_initializer)(x)         #(29, 29, 1)\n    \n    return tf.keras.models.Model(inputs=input_,outputs=output)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:43.611297Z","iopub.execute_input":"2023-12-03T08:55:43.611602Z","iopub.status.idle":"2023-12-03T08:55:43.623621Z","shell.execute_reply.started":"2023-12-03T08:55:43.611574Z","shell.execute_reply":"2023-12-03T08:55:43.622555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"white2black_disc = PATCH_discriminator()  ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:44.119753Z","iopub.execute_input":"2023-12-03T08:55:44.120173Z","iopub.status.idle":"2023-12-03T08:55:44.347166Z","shell.execute_reply.started":"2023-12-03T08:55:44.120141Z","shell.execute_reply":"2023-12-03T08:55:44.346300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"black2white_disc = PATCH_discriminator() ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:44.675742Z","iopub.execute_input":"2023-12-03T08:55:44.676614Z","iopub.status.idle":"2023-12-03T08:55:44.903648Z","shell.execute_reply.started":"2023-12-03T08:55:44.676579Z","shell.execute_reply":"2023-12-03T08:55:44.902239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_cycle(gen_1,gen_2,input_image):\n    '''generate a full cycle of images using given generators'''\n    gen_img_1 = gen_1(input_image,training=True)\n    gen_img_2 = gen_2(gen_img_1,training=True)\n    \n    return gen_img_1,gen_img_2\n\n\ndef calc_and_apply_gradients(tape,\n                             model,\n                             loss,\n                             optimizer):\n    '''Apply gradients for a given model using given optimizer''' \n   \n    gradients = tape.gradient(loss,model.trainable_variables)\n    \n    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n    return \n\ndef discriminator_loss(real, generated):\n    '''discriminator Binary CrossEntropy loss'''\n    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real), real)\n\n    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(generated), generated)\n\n    total_disc_loss = real_loss + generated_loss\n\n    return total_disc_loss * 0.5\n\n# Generator Adverserial loss\ndef generator_loss(generated):\n    '''adverserial generator loss (BCE)'''\n    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(generated), generated)\n\n    \n# Cycle consistency loss \n    \ndef calc_cycle_loss(real_image, cycled_image, LAMBDA):\n    '''pixel wise cycle loss between original image and cycled image'''\n    mae_loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n\n    return LAMBDA * mae_loss\n\n\n# identity loss\ndef identity_loss(real_image, same_image, LAMBDA):    \n    mae_loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return LAMBDA * 0.5 * mae_loss","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:45.336570Z","iopub.execute_input":"2023-12-03T08:55:45.337009Z","iopub.status.idle":"2023-12-03T08:55:45.347818Z","shell.execute_reply.started":"2023-12-03T08:55:45.336974Z","shell.execute_reply":"2023-12-03T08:55:45.346588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGAN(tf.keras.models.Model):\n    def __init__(self,\n                 lambda_cycle=10):\n        super(CycleGAN, self).__init__()\n        self.gen_w2b = white2black_gen\n        self.gen_b2w = black2white_gen \n        self.disc_w2b = white2black_disc \n        self.disc_b2w = black2white_disc \n        self.lambda_cycle = lambda_cycle \n    \n    \n    def compile(self,\n                gen_loss_fn,\n                disc_loss_fn,\n                cycle_loss_fn,\n                identity_loss_fn,\n                common_opt = tf.keras.optimizers.legacy.Adam(learning_rate = CFG.learning_rate,beta_1 = 0.5)):\n        \n        super(CycleGAN, self).compile()\n        \n        # -------optimizers ---------\n        self.opt_gen_w2b = common_opt\n        self.opt_gen_b2w = common_opt\n        self.opt_disc_w2b = common_opt\n        self.opt_disc_b2w = common_opt\n        \n        \n        # -------losses ---------\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n        \n    def train_step(self, batch_data):\n        white_image, black_image = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            \n            fake_black,cycled_white = generate_cycle(self.gen_w2b,\n                                                     self.gen_b2w,\n                                                     white_image) \n\n            fake_white,cycled_black = generate_cycle(self.gen_b2w,\n                                                   self.gen_w2b,\n                                                   black_image)\n            \n            #---------- generating itself (for identity loss)\n            iden_white = self.gen_w2b(black_image, training=True)\n            iden_black = self.gen_b2w(white_image, training=True)\n\n            # -----------discriminator on real images\n            disc_black = self.disc_w2b(black_image, training=True)\n            disc_white = self.disc_b2w(white_image, training=True)\n\n            # -----------discriminator on fake images-----------------\n            disc_fake_black   = self.disc_w2b(fake_black, training=True)\n            disc_fake_white = self.disc_b2w(fake_white, training=True)\n\n            # -------------------------generator loss-------------\n               #---1)adverserial loss\n            black_gen_loss = self.gen_loss_fn(disc_fake_black) \n            white_gen_loss = self.gen_loss_fn(disc_fake_white)\n\n                #---2)Cycle loss loss\n            total_cycle_loss = self.cycle_loss_fn(black_image, cycled_black, self.lambda_cycle) + self.cycle_loss_fn(white_image, cycled_white, self.lambda_cycle)\n\n                # +++++3) Total Gen loss (white gen and black gen)\n            total_gen_w2b_loss = black_gen_loss + total_cycle_loss + self.identity_loss_fn(black_image, iden_black,self.lambda_cycle)\n            total_gen_b2w_loss = white_gen_loss + total_cycle_loss + self.identity_loss_fn(white_image, iden_white, self.lambda_cycle)\n            \n            \n            # -------------------------Discriminator loss-------------\n            black_disc_loss = self.disc_loss_fn(disc_black, disc_fake_black)  # check classifying generated and real black\n            white_disc_loss = self.disc_loss_fn(disc_white, disc_fake_white)        # check  classifying generated and real white\n\n        ## ------------------------- Calculating and Updating gradients------------------\n        \n        # white->black gen gradeints\n        _ = calc_and_apply_gradients(tape=tape,\n                                     model= self.gen_w2b,\n                                     loss = total_gen_w2b_loss,\n                                     optimizer = self.opt_gen_w2b)\n        \n        # black - >white  gen gradeints\n        _ = calc_and_apply_gradients(tape=tape,\n                                     model= self.gen_b2w,\n                                     loss = total_gen_b2w_loss,\n                                     optimizer = self.opt_gen_b2w)\n        \n        #  discrim gradients (classifies black images)\n        _ = calc_and_apply_gradients(tape=tape,\n                                     model= self.disc_w2b,\n                                     loss = black_disc_loss,\n                                     optimizer = self.opt_disc_w2b)\n        \n        # white discrim gradients (classifies white images)\n        _ = calc_and_apply_gradients(tape=tape,\n                                     model= self.disc_b2w,\n                                     loss = white_disc_loss,\n                                     optimizer = self.opt_disc_b2w)\n        \n        \n        return {'gen_w2b_loss': total_gen_w2b_loss,\n                'gen_b2w_loss': total_gen_b2w_loss,\n                'disc_white_loss': white_disc_loss,\n                'disc_black_loss': black_disc_loss\n               }\n        \n    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:46.133442Z","iopub.execute_input":"2023-12-03T08:55:46.133787Z","iopub.status.idle":"2023-12-03T08:55:46.155060Z","shell.execute_reply.started":"2023-12-03T08:55:46.133759Z","shell.execute_reply":"2023-12-03T08:55:46.153893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creat a instance of Cycle gan \ngan = CycleGAN()\n\n\n#complie with the losses \ngan.compile(gen_loss_fn = generator_loss, disc_loss_fn  = discriminator_loss, cycle_loss_fn = calc_cycle_loss, identity_loss_fn = identity_loss)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:46.914108Z","iopub.execute_input":"2023-12-03T08:55:46.914762Z","iopub.status.idle":"2023-12-03T08:55:46.938976Z","shell.execute_reply.started":"2023-12-03T08:55:46.914729Z","shell.execute_reply":"2023-12-03T08:55:46.938126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learning rate schedule \n\ndef scheduler(epoch, \n              lr,\n              decay_rate = 0.05,\n              warm_up_period = 10):\n    \n    if epoch < warm_up_period:\n        return lr\n    elif (epoch > warm_up_period and epoch<40):\n        return lr * tf.math.exp(decay_rate)\n    else:\n        return lr * tf.math.exp(decay_rate*2)\n        \nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler,\n                                                        verbose = 0)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:47.286290Z","iopub.execute_input":"2023-12-03T08:55:47.287001Z","iopub.status.idle":"2023-12-03T08:55:47.293950Z","shell.execute_reply.started":"2023-12-03T08:55:47.286948Z","shell.execute_reply":"2023-12-03T08:55:47.292639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_samples(ds, n_samples):\n    ds_iter = iter(ds)\n    for n_sample in range(n_samples):\n        example_sample = next(ds_iter)\n        plt.subplot(121)\n        plt.imshow(example_sample[0] * 0.5 + 0.5)\n        plt.axis('off')\n        plt.show()\n        \ndef display_generated_samples(ds, model, n_samples):\n    ds_iter = iter(ds)\n    for n_sample in range(n_samples):\n        example_sample = next(ds_iter)\n        generated_sample = model.predict(example_sample)\n        \n        f = plt.figure(figsize=(16,8))\n        \n        plt.subplot(121)\n        plt.title('Input image')\n        plt.imshow(example_sample[0] * 0.5 + 0.5)\n        plt.axis('off')\n        \n        plt.subplot(122)\n        plt.title('Generated image')\n        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n        plt.axis('off')\n        plt.show()\n        \ndef evaluate_cycle(ds, generator_a, generator_b, n_samples=1):\n    fig, axes = plt.subplots(n_samples, 3, figsize=(22, (n_samples*6)))\n    axes = axes.flatten()\n    \n    ds_iter = iter(ds)\n    for n_sample in range(n_samples):\n        idx = n_sample*3\n        example_sample = next(ds_iter)\n        generated_a_sample = generator_a.predict(example_sample)\n        generated_b_sample = generator_b.predict(generated_a_sample)\n        \n        axes[idx].set_title('Input image', fontsize=18)\n        axes[idx].imshow(example_sample[0] * 0.5 + 0.5)\n        axes[idx].axis('off')\n        \n        axes[idx+1].set_title('Generated image', fontsize=18)\n        axes[idx+1].imshow(generated_a_sample[0] * 0.5 + 0.5)\n        axes[idx+1].axis('off')\n        \n        axes[idx+2].set_title('Cycled image', fontsize=18)\n        axes[idx+2].imshow(generated_b_sample[0] * 0.5 + 0.5)\n        axes[idx+2].axis('off')\n        \n    plt.show()\n        \ndef predict_and_save(input_ds, generator_model, output_path):\n    i = 1\n    for img in input_ds:\n        prediction = generator_model(img, training=False)[0].numpy() # make predition\n        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n        im = PIL.Image.fromarray(prediction)\n        im.save(f'{output_path}{str(i)}.jpg')\n        i += 1\n        \n        \ndef save_models(g_model_AtoB, g_model_BtoA):\n    filename1 = 'g_model_AtoB.h5'\n    g_model_AtoB.save(filename1)\n    filename2 = 'g_model_BtoA.h5'\n    g_model_BtoA.save(filename2)\n    print(f'--->Saved: {filename1}, {filename2}')\n\n# Callback\nclass GANMonitor(tf.keras.callbacks.Callback):\n    \"\"\"A callback to generate and save images after each epoch\"\"\"\n\n    def __init__(self, \n                 num_img=1, \n                 white_paths='generated_white', \n                 black_paths='generated_black'):\n        self.num_img = num_img\n        self.white_paths = white_paths\n        self.black_paths = black_paths\n        \n        # dir to save genereated white images\n        if not os.path.exists(self.white_paths):\n            os.makedirs(self.white_paths)\n            \n            \n        # dir to save genereated black images\n        if not os.path.exists(self.black_paths):\n            os.makedirs(self.black_paths)\n            \n    def on_epoch_end(self, epoch, logs=None):\n        #generated black \n        for i, img in enumerate(white_eval.take(self.num_img)):   \n            prediction = white2black_gen(img, training=False)[0].numpy()\n            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n            prediction = PIL.Image.fromarray(prediction)\n            prediction.save(f'{self.black_paths}/generated_{i}_{epoch+1}.png')\n            \n        # generated white images \n        for i, img in enumerate(black_eval.take(self.num_img)):\n            prediction = black2white_gen(img, training=False)[0].numpy()\n            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n            prediction = PIL.Image.fromarray(prediction)\n            prediction.save(f'{self.white_paths}/generated_{i}_{epoch+1}.png')\n            \n        save_models(white2black_gen, black2white_gen)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T08:55:47.955628Z","iopub.execute_input":"2023-12-03T08:55:47.956015Z","iopub.status.idle":"2023-12-03T08:55:47.978684Z","shell.execute_reply.started":"2023-12-03T08:55:47.955982Z","shell.execute_reply":"2023-12-03T08:55:47.977649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 70\ncallbacks = [lr_scheduler,GANMonitor()]\nsteps_per_epoch = 20\n\n\nhistory = gan.fit(Train_Dataset,\n                epochs = EPOCHS,\n                steps_per_epoch=steps_per_epoch,\n                callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:26:37.483933Z","iopub.execute_input":"2023-12-03T10:26:37.484380Z","iopub.status.idle":"2023-12-03T10:59:59.423160Z","shell.execute_reply.started":"2023-12-03T10:26:37.484334Z","shell.execute_reply":"2023-12-03T10:59:59.422229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_generated_samples(black_eval.take(10), black2white_gen, 5)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:00:48.414431Z","iopub.execute_input":"2023-12-03T11:00:48.415202Z","iopub.status.idle":"2023-12-03T11:00:52.761236Z","shell.execute_reply.started":"2023-12-03T11:00:48.415164Z","shell.execute_reply":"2023-12-03T11:00:52.760308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_generated_samples(white_eval.take(10), white2black_gen, 5)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:01:22.966830Z","iopub.execute_input":"2023-12-03T11:01:22.967784Z","iopub.status.idle":"2023-12-03T11:01:27.523087Z","shell.execute_reply.started":"2023-12-03T11:01:22.967747Z","shell.execute_reply":"2023-12-03T11:01:27.521998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel_AtoB = load_model('/kaggle/working/g_model_AtoB.h5')\nmodel_BtoA = load_model('/kaggle/working/g_model_BtoA.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:23:13.455996Z","iopub.execute_input":"2023-12-03T10:23:13.456754Z","iopub.status.idle":"2023-12-03T10:23:14.595091Z","shell.execute_reply.started":"2023-12-03T10:23:13.456717Z","shell.execute_reply":"2023-12-03T10:23:14.594289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_generated_samples(white_eval.take(10), model_AtoB, 2)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:23:16.046586Z","iopub.execute_input":"2023-12-03T10:23:16.046980Z","iopub.status.idle":"2023-12-03T10:23:18.434824Z","shell.execute_reply.started":"2023-12-03T10:23:16.046950Z","shell.execute_reply":"2023-12-03T10:23:18.433754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_generated_samples(black_eval.take(10), model_BtoA, 2)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:23:18.436665Z","iopub.execute_input":"2023-12-03T10:23:18.437044Z","iopub.status.idle":"2023-12-03T10:23:21.383126Z","shell.execute_reply.started":"2023-12-03T10:23:18.437010Z","shell.execute_reply":"2023-12-03T10:23:21.381940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nfrom io import BytesIO\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\nimport numpy as np\n\n\n# URL of the image\nimg_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZ2iDYguRA_8Yf_DdQ30FAtP9e4xLdh7HKkw&usqp=CAU'\n# Download the image\nresponse = requests.get(img_url)\nimg = Image.open(BytesIO(response.content))\n\n# Resize the image to the desired target size\nimg = img.resize((512, 512))\n\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\n\npredictions = model_AtoB.predict(img_array)\n\n# print(\"Pred: \", predictions)\nprint(\"Ouput Image\", output_image)\n\noutput_image = predictions[0] \n# image.save_img('output_image.jpg', output_image) \nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title('Input Image')\nplt.axis('off')\n\n# Display the generated output image\nplt.subplot(1, 2, 2)\nplt.imshow(output_image)\nplt.title('Generated Output')\nplt.axis('off')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T16:42:49.817539Z","iopub.execute_input":"2023-12-01T16:42:49.818437Z","iopub.status.idle":"2023-12-01T16:42:50.387441Z","shell.execute_reply.started":"2023-12-01T16:42:49.818398Z","shell.execute_reply":"2023-12-01T16:42:50.386541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\nimport numpy as np\n\nimg_path = '/kaggle/input/black-white-shirts/BlackAndWhiteShirts/white/1034.jpg'\nimg = image.load_img(img_path, target_size=(512, 512))\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\n\npredictions = model_AtoB.predict(img_array)\n\n\noutput_image = predictions[0] \n# image.save_img('output_image.jpg', output_image) \nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title('Input Image')\nplt.axis('off')\n\n# Display the generated output image\nplt.subplot(1, 2, 2)\nplt.imshow(output_image)\nplt.title('Generated Output')\nplt.axis('off')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:38:22.368453Z","iopub.execute_input":"2023-12-01T15:38:22.368833Z","iopub.status.idle":"2023-12-01T15:38:22.905494Z","shell.execute_reply.started":"2023-12-01T15:38:22.368805Z","shell.execute_reply":"2023-12-01T15:38:22.904549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}